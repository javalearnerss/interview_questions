
Consumers (Deep Dive)
0. What is heartbeat concept for consumer.
    Heartbeat in Kafka is how a consumer tells Kafka:
    üëâ ‚ÄúI‚Äôm alive and still part of the consumer group.‚Äù

    How it works:
        - Each consumer periodically sends heartbeats to the Group Coordinator broker.
        - As long as heartbeats arrive on time, the consumer keeps its partition assignment.
        - If heartbeats stop (crash, GC pause, network issue):
            - Coordinator marks the consumer dead
            - Triggers a rebalance
            - Partitions are reassigned to other consumers

    Important configs (interview favorites):
        - heartbeat.interval.ms ‚Üí how often heartbeats are sent
        - session.timeout.ms ‚Üí max time without heartbeat before consumer is considered dead
        - max.poll.interval.ms ‚Üí max time between poll() calls (processing watchdog)

1. How does Kafka consumer group coordination work?
    - When a consumer starts, it joins a consumer group and discovers the Group Coordinator 
       (a Kafka broker responsible for that group).
    - Consumers send JoinGroup requests; the coordinator collects all members.
    - A leader consumer (chosen by the coordinator) runs the partition assignment strategy 
       (range, round-robin, sticky).
    - The coordinator distributes assignments to all consumers.
    - Consumers start polling only their assigned partitions and send heartbeats to stay active.
    - If a consumer joins, leaves, or fails, the coordinator triggers a rebalance.
    Note : A consumer group is created on the Kafka broker (Group Coordinator) automatically 
    when the first consumer with a new group.id joins.
        - There is no explicit ‚Äúcreate consumer group‚Äù command.
        - When a consumer starts with a new group.id:
        - It sends a JoinGroup request to the broker acting as the Group Coordinator.
        - The coordinator creates group metadata in memory.
        - Offsets and group state are stored in the internal topic __consumer_offsets.
        - From then on, that group.id exists and is managed by the broker.

2. What causes consumer rebalancing?
    Consumer rebalancing in Kafka happens when the membership or assignment of a consumer group changes.
    Common causes include a consumer joining or leaving the group, a consumer failure or missed heartbeats, 
      topic partition changes, or configuration changes (like assignment strategy).
    When this happens, Kafka pauses consumption and redistributes partitions among active consumers.

3. Why are frequent rebalances dangerous?
    Frequent rebalances are dangerous because:
     - Consumption stops during rebalancing, directly impacting throughput
     - They increase consumer lag and end-to-end latency
     - They can cause duplicate processing or missed commits
     - They indicate an unstable consumer group, often due to bad configs or slow consumers

4. What is the role of poll() in Kafka consumers?
    while (running) {
        ConsumerRecords<String, String> records =
                consumer.poll(Duration.ofMillis(100));
        for (ConsumerRecord<String, String> record : records) {
            process(record);
        }
        consumer.commitSync(); // or async
    }
    - poll() is the core method that drives a Kafka consumer.
    - It fetches records from the broker and sends heartbeats to the group coordinator to 
            keep the consumer alive.
    - If poll() is not called within the configured interval, Kafka assumes the consumer 
        is dead and triggers a rebalance.
    Key configs tied to poll()
        max.poll.interval.ms ‚Üí max time between poll() calls
        max.poll.records ‚Üí how many records returned per poll()
        session.timeout.ms & heartbeat.interval.ms ‚Üí liveness checks
    In Spring Boot, you usually don‚Äôt call poll() yourself. Spring Kafka runs a background 
    consumer loop that continuously calls poll() for you.

5. What happens if poll() is delayed too long?
    If poll() is delayed too long:
        The consumer stops sending heartbeats
        The group coordinator marks it as dead
        A rebalance is triggered
        Its partitions are revoked and reassigned to other consumers
        The slow consumer may later rejoin, causing more rebalances and possible duplicates

6. How does max.poll.interval.ms affect consumers?
    - max.poll.interval.ms defines the maximum time a consumer can take to process records 
      between two poll() calls.
    - If processing takes longer than this value, Kafka assumes the consumer is stuck, 
      removes it from the group, and triggers a rebalance.

7. Difference between auto-commit and manual commit?
    - Auto-commit
        Kafka commits offsets automatically at intervals
        Simple to use, but can cause message loss or duplicates
        Less control over when a message is considered processed

    - Manual commit
        Application commits offsets explicitly after processing
        Gives full control and reliability
        Slightly more code, but safer for production

8. When can offsets be committed but processing fails?
    Offsets can be committed but processing can still fail in these cases:
    - Auto-commit enabled: Offsets are committed before processing completes, and the app crashes 
       during processing.
    - Manual commit done too early: The app commits offsets before writing to DB / downstream system, 
       then fails.
    - Async commit (commitAsync): Commit succeeds, but processing fails immediately after.
    - External system failure: Kafka offset is committed, but DB/API update fails.

9. How do you design idempotent consumers?
    To design idempotent consumers, make your processing safe to run more than once for the same message 
    (because Kafka is often at-least-once).

    Common patterns (used in production)
    1) Use a unique event id + dedup store
        Include eventId (UUID/orderId+version) in each message
        Before processing, check a table/cache: ‚Äúhave I processed this eventId?‚Äù
        If yes ‚Üí skip; if no ‚Üí process and record it

    2) Make the downstream write idempotent
        Use UPSERT / INSERT ‚Ä¶ ON CONFLICT DO NOTHING
        Use unique constraints on eventId or (businessKey, version)
        Avoid ‚Äúadd 10‚Äù updates; prefer ‚Äúset state to X‚Äù updates

    3) Transactional pattern (best)
        In one DB transaction:
        apply business update
        store eventId (or update a version)
        Commit Kafka offset after DB commit

    4) Use exactly-once tools when applicable
        Kafka Streams EOS / transactions can help for Kafka‚ÜíKafka pipelines, but DB still needs idempotency.

10.What consumer bugs have caused production incidents?
    Here are real consumer bugs that commonly cause production incidents, phrased the way interviewers like (symptom + root cause).
    - Rebalance storm: poll() blocked by long processing ‚Üí missed heartbeats / max.poll.interval.ms exceeded ‚Üí constant rebalances, no progress.
    - Duplicate processing: manual commit done after processing but downstream isn‚Äôt idempotent ‚Üí retries/rebalances reprocess messages and create duplicates.
    - Message loss: offsets committed too early (auto-commit or wrong manual commit timing) ‚Üí crash after commit ‚Üí records skipped forever.
    - Hot partition lag: bad keying (same key) ‚Üí one partition overloaded ‚Üí one consumer maxed out, group looks ‚Äúhealthy‚Äù but latency spikes.
    - Infinite retry loop: poison message keeps failing and is retried forever ‚Üí partition stuck, backlog grows.
    - OOM / GC pauses: fetching huge batches or large messages ‚Üí JVM GC stalls ‚Üí missed heartbeats ‚Üí rebalances + lag.
    - Threading mistake: using one KafkaConsumer across multiple threads ‚Üí unstable behavior, missed polls, exceptions, stalled consumption.
    - Wrong offset reset: misused auto.offset.reset (e.g., latest in a new group) ‚Üí starts after existing data ‚Üí ‚Äúmissing events‚Äù incident.
    - Bad error handling: swallowing exceptions and continuing commits ‚Üí silently drops failed records.
    - Under-provisioned consumers: too few consumers vs partitions or too slow processing ‚Üí lag grows until downstream SLAs break.

