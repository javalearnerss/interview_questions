2. Java Memory Model (JMM)
    
    1. What is happens-before relationship?
    2. How volatile works internally?
    3. Difference between volatile and synchronized?
    4. Safe publication techniques?
    5. What is instruction reordering?
    6. What is false sharing?
    7. What is padding in concurrency?

**********************************************************************************************************************
Java Memory Model (JMM)

    Java Memory Model defines how threads access shared memory and ensures visibility, ordering, and 
    atomicity using constructs like synchronized, volatile, and happens-before rules.

    visibility problem:
        Imagine a Java application where multiple threads are working at the same time. There is a shared main memory, 
        which stores the real and final values of variables. Each thread, however, does not always directly use this main memory. 
        For performance reasons, each thread keeps a local copy of variables in its working memory (CPU cache or registers) and 
        performs operations using that local copy.

        Now suppose Thread A updates a value. It may first update its working memory and only later write that value back to main memory. 
        Meanwhile, Thread B may still be reading the old value from its own working memory, not knowing that Thread A has already changed it. 
        This situation is called a visibility problem — one thread’s update is not immediately visible to other threads.

    instruction reordering:
        Another important issue is instruction reordering. To make programs run faster, the CPU and compiler are allowed to rearrange instructions 
        if the final single-threaded result remains the same. For example, if two independent instructions exist, the CPU might execute them in 
        a different order to optimize performance. But in multithreading, this can cause unexpected results because another thread may observe 
        operations happening in a different order than written in code. This is called the instruction reordering problem.

    Atomicity problem
        Now consider the atomicity problem. Some operations look like a single step in code but actually happen in multiple steps internally. 
        For example, incrementing a variable (count++) involves reading the value, increasing it, and writing it back. 
        If two threads try to update the same variable at the same time, their operations can overlap. This can cause lost updates or incorrect 
        values because the operation was not completed as one indivisible step. That is called an atomicity problem.

        class AtomicityProblemExample {

            static int count = 0;

            public static void main(String[] args) throws Exception {

                Thread t1 = new Thread(() -> {
                    for (int i = 0; i < 10000; i++) {
                        count++;   // NOT ATOMIC
                    }
                });

                Thread t2 = new Thread(() -> {
                    for (int i = 0; i < 10000; i++) {
                        count++;   // NOT ATOMIC
                    }
                });

                t1.start();
                t2.start();

                t1.join();
                t2.join();

                System.out.println("Final Count = " + count);
            }
        }

        Expected Result
        Final Count = 20000

        ❌ Actual Possible Result
        Final Count = 15342   (or any random < 20000)

        Why This Happens (count++ Internal Steps)

        count++ is actually 3 operations:
            1. Read count from memory
            2. Add 1
            3. Write back to memory

    The Java Memory Model solves these problems by defining strict rules on how and when threads must read from and write to main memory. 
    It also provides tools like synchronized (ensures visibility, ordering, atomicity) and volatile (ensures visibility and ordering). 
    It also defines happens-before rules, which guarantee that if one operation happens-before another, then the second operation will 
    see the results of the first.


    ------------------------------------------------------------------------------------------------------------

    The whiteboard analogy version:

    Imagine a Java application running with multiple threads. Think of Main Memory as a central whiteboard in an office where important shared 
    information is written. All employees (threads) are supposed to read and write from this whiteboard. But for speed, each employee keeps a 
    personal notebook (Working Memory / CPU Cache) where they copy some information from the whiteboard. They mostly work using their notebook 
    instead of going back to the whiteboard every time.

    Now here’s the problem. Suppose Employee A (Thread A) updates a value in their notebook and later updates the whiteboard. 
    But Employee B (Thread B) is still working using an old value written in their notebook and has not checked the whiteboard again. 
    So Employee B continues using outdated information. This is called a visibility problem.

    Sometimes, to finish work faster, employees may rearrange the order of tasks if they think the final result will be the same. 
    But if another employee is watching the whiteboard at the same time, they might see steps happening in a different order than expected. 
    This is similar to the instruction reordering problem.

    Now imagine two employees try to update the same number on the whiteboard at the same time. One reads the value, starts updating it, 
    but before finishing, another employee reads the old value and writes back their update. The final number on the whiteboard becomes incorrect. 
    This is the atomicity problem, where an operation that should happen in one complete step gets interrupted.

    This is where the Java Memory Model acts like strict office rules. JMM says how and when threads must sync their notebooks with the whiteboard. 
    It defines rules so that when one thread updates data, other threads will see it correctly and in the right order. To enforce these rules, 
    Java provides tools like synchronized, volatile, and final.

    For example, when you use synchronized, it’s like forcing the employee to go to the whiteboard directly before reading or writing, 
    ensuring everyone sees the latest value. When you use volatile, it means the thread must always check the whiteboard before using 
    the value — no outdated notebook copies allowed. JMM also defines something called the Happens-Before relationship, 
    which is like saying: If action A happens before action B, then B is guaranteed to see the results of A.

******************************************************************************************************************************************
1. What is happens-before relationship?

    Common Happens-Before Rules (Very Important for Interview)
        ✔ Lock Release → Happens-before → Lock Acquire
        ✔ Thread Start → Happens-before → Thread Execution
        ✔ Volatile Write → Happens-before → Volatile Read
        ✔ Object Constructor → Happens-before → Finalizer

    1. "Happens-before" is a rule in the Java Memory Model (JMM) that defines when one action's effects (like writing to a variable) are 
    guaranteed to be visible to another action (like reading that variable) in a multithreaded program.

    2. If Action A happens-before Action B, then:
        All changes made by A are visible to B.
        A is guaranteed to execute before B (from B’s perspective).

    3. Without a happens-before relationship, threads may see stale or inconsistent data due to CPU caching or compiler optimizations.

    4. Happens-before relationships are established by:
        Synchronization (entering/exiting synchronized blocks)
        Volatile variable writes/reads
        Thread start/join
        Program order within a single thread

        // Java
        public class HappensBeforeDemo {
            static int data = 0;
            static boolean ready = false;

            public static void main(String[] args) throws InterruptedException {

                Thread writer = new Thread(() -> {
                    data = 100;   // (1) Write to data
                    ready = true; // (2) Write to ready
                });

                Thread reader = new Thread(() -> {
                    while (!ready) {}       // (3) Wait for ready
                    System.out.println(data); // (4) Read data
                });

                writer.start();
                reader.start();
                writer.join();
                reader.join();
            }
        }

        If ready is not volatile or not synchronized, the reader thread may print 0, because the write to data at (1) may not be visible 
        to the reader at (4).

        If you declare ready as volatile, the write to ready at (2) happens-before the read at (3), and all previous writes (like to data) 
        are also visible to the reader. Now, the reader will always print 100.

        Summary:
            "Happens-before" ensures that memory writes by one thread are visible to another, and that actions are executed in a predictable order.
            Use synchronization or volatile variables to establish happens-before relationships and avoid concurrency bugs.

        Analogy:
            Imagine two coworkers, Alice and Bob, sharing an office whiteboard.
            Alice writes a number on the whiteboard (Action A).
            Bob wants to read the number (Action B).
            If there’s no rule, Bob might look at the whiteboard before Alice finishes writing, so he could see an old or incomplete number.
            If they agree on a rule — Alice puts the marker cap on the board after writing, and Bob only reads after seeing the cap — then Bob is guaranteed to see what Alice wrote.
            This rule is like a "happens-before" relationship: Alice’s writing (A) happens-before Bob’s reading (B), so Bob always sees the latest value.
            In Java, synchronization or volatile variables are like the marker cap — they establish the rule that guarantees visibility and order between threads.

        The Java Memory Model (JMM) defines the rules for "happens-before" relationships.
        The JVM and CPU use memory barriers (fences) to enforce ordering and visibility.
        Synchronization constructs (synchronized blocks, volatile variables, thread start/join) insert these barriers.
        The compiler and runtime ensure that code is not reordered across these barriers.

        Implementation details:
            Entering/exiting a synchronized block inserts acquire/release memory barriers.
            Writing to a volatile variable inserts a store barrier; reading inserts a load barrier.
            Thread start/join methods have built-in synchronization to establish ordering.
            These barriers flush CPU caches and prevent instruction reordering, ensuring visibility and order.

        | **Mechanism**     | **How it guarantees happens-before**          |
        | ----------------- | --------------------------------------------- |
        | synchronized      | Memory barriers on lock/unlock                |
        | volatile          | Barriers on volatile read/write               |
        | Thread.start/join | Built-in synchronization in JVM               |
        | Program order     | Compiler/JVM preserves order in single thread |



******************************************************************************************************************************************
2. How volatile works internally?

    1. Volatile variables in Java ensure that updates to a variable are immediately visible to all threads.

    2. Internally, the JVM uses memory barriers (also called fences) to enforce this:
        On a volatile write, a store barrier is inserted so all previous writes are flushed to main memory.
        On a volatile read, a load barrier is inserted so the value is read from main memory, not from a thread-local cache.

    3. These barriers prevent the CPU and compiler from reordering instructions across the volatile access, ensuring correct ordering and visibility.

    4. Volatile is suitable for simple flags or state variables, but not for compound actions (like increment), which require atomicity.

    // Java
    public class VolatileDemo {
        private int data = 0;
        private volatile boolean flag = false;

        // Writer thread: updates data, then sets flag
        public void writer() {
            data = 42; // Write to data
            System.out.println("Writer: data set to 42");
            flag = true; // Store barrier: ensures data write is visible before flag is set
            System.out.println("Writer: flag set to true");
        }

        // Reader thread: waits for flag, then reads data
        public void reader() {
            while (!flag) {
                // Busy-wait until flag is true
            }
            // Load barrier: ensures latest value of data is visible after flag is true
            System.out.println("Reader: flag is true, data = " + data);
        }
    }

******************************************************************************************************************************************
3. Difference between volatile and synchronized?

    Define volatile: ensures visibility and ordering of variable updates across threads using memory barriers.

    Define synchronized: ensures visibility, ordering, and mutual exclusion (atomicity) for code blocks or methods using monitor locks.

    Summarize differences in a table.

    Provide a Java code example showing both.

    | Feature      | volatile              | synchronized               |
    | ------------ | --------------------- | -------------------------- |
    | Visibility   | Yes (memory barriers) | Yes (lock/unlock barriers) |
    | Ordering     | Yes                   | Yes                        |
    | Atomicity    | No                    | Yes (mutual exclusion)     |
    | Usage        | Variable              | Block/method               |
    | Locking      | No                    | Yes                        |
    | Compound ops | Not safe              | Safe                       |

    // Java
    public class VolatileVsSynchronized {
        private volatile int volatileCounter = 0;
        private int syncCounter = 0;

        // Volatile: visibility, not atomicity
        public void incrementVolatile() {
            volatileCounter++; // Not atomic, may have race conditions
        }

        // Synchronized: visibility + atomicity
        public synchronized void incrementSync() {
            syncCounter++; // Atomic, safe from race conditions
        }
    }

    Analogy:

    Imagine two coworkers, Alice and Bob, sharing an office whiteboard.

    Volatile analogy:
        Alice writes a note on the whiteboard and puts a "Read Now" sticky note.
        Bob always checks for the sticky note before reading.
        The sticky note ensures Bob sees the latest note, but if both try to write at the same time, the notes may overlap 
        (no protection against simultaneous writes).

    Synchronized analogy:
        The whiteboard is in a meeting room with a lock.
        Alice locks the room, writes her note, then unlocks it.
        Bob waits outside until the room is unlocked, then locks it himself to read or write.

    This ensures only one person accesses the whiteboard at a time, so notes never overlap and everyone sees the latest version.

******************************************************************************************************************************************
 4. Safe publication techniques?   


******************************************************************************************************************************************
 5. What is instruction reordering?

    Instruction reordering is when the compiler, JVM, or CPU changes the order of instructions to optimize performance.
    In single-threaded code, this is safe if the final result is unchanged.
    In multithreaded code, reordering can cause one thread to see stale or inconsistent data.

    // Java
    public class InstructionReorderingDemo {
        int a = 0;
        boolean flag = false;

        // Writer thread
        public void writer() {
            a = 1;       // (1) Write to a
            flag = true; // (2) Write to flag
        }

        // Reader thread
        public void reader() {
            if (flag) {              // (3) Read flag
                System.out.println(a); // (4) Read a
            }
        }

        public static void main(String[] args) {
            // Start writer and reader threads
        }
    }

    1. Without synchronization or volatile, the JVM or CPU may reorder (1) and (2) in the writer, so flag could be set to true before a is set to 1.

    2. The reader thread could see flag as true but still see a as 0, because the write to a hasn't happened yet from its perspective.

    3. This is possible because, in the absence of a happens-before relationship, the Java Memory Model allows such reordering for optimization.

    4. Adding volatile to flag or using synchronized blocks prevents this reordering by inserting memory barriers, ensuring that writes to 
     are visible before flag is set to true, and the reader will always see the correct value of a after seeing flag as true.

******************************************************************************************************************************************
