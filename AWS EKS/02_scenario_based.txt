ğŸ”¥ Cluster Creation & Architecture Scenarios

1. Your EKS cluster creation succeeds, but no pods can be scheduled. What do you check first?
    Chapter 1: â€œDo I even have workers?â€
        First thought: Kubernetes canâ€™t schedule without nodes.
        You check: kubectl get nodes
        The cluster is fine, but there are no EC2 workers.
        You immediately look at: Node group size, Auto Scaling Group, Instance launch failures
    
    Chapter 2: â€œThe workers exist, but are they alive?â€
        You do see nodes â€” but theyâ€™re NotReady.
        You suspect: CNI plugin not working,  Node IAM role missing permissions,
        Security groups or subnets blocking control-plane traffic
    
    Chapter 3: â€œWhy is my pod being rejected?â€
        Nodes are Ready, yet pods are still Pending.
        You interrogate the pod:  kubectl describe pod <pod>
        At the bottom, the Events confess everything:
        Insufficient CPU, NodeSelector doesnâ€™t match,  Untolerated taint, 0/3 nodes available
    
    Chapter 4: â€œThe silent killersâ€
        Now you check the usual suspects:
            1. Node group scaled to 0
            2. Pods asking for more CPU/memory than the instance has
            3. Nodes tainted, pods missing tolerations
            4. Hard node affinity that matches nothing

2. Your EKS control plane is healthy, but kubectl intermittently fails. How do you debug this?

3. A cluster works in one AWS account but not another with the same Terraform code. Why?

4. Youâ€™re asked to run prod and non-prod workloads in the same cluster. What could go wrong?
    A lot can go wrong because youâ€™re mixing blast radius, trust boundaries, and noisy neighbors.

    1) Blast radius becomes shared
    Example: A bad non-prod deployment (crashloop + retries) floods the API server / etcd and impacts prod scheduling and rollouts.

    2) Noisy neighbor resource contention
    Example: A load test in staging eats CPU/memory, evicts prod pods, or causes HPA to scale slowly because nodes are saturated.

    3) Security boundary breaks (RBAC / secrets)
    Example: A dev with non-prod access can accidentally get access to prod namespaces/secrets due to RBAC misconfig or shared service accounts.

    4) Network isolation is harder
    Example: Without strict NetworkPolicies, a non-prod pod can call prod services directly (data leakage / unintended writes).

    5) Shared cluster-level components become single point of failure
    Example: Non-prod teams upgrade Ingress Controller / CNI / CoreDNS for testing and it breaks prod traffic resolution.

    6) Upgrade and change management conflict
    Example: Non-prod wants frequent version bumps/add-ons; prod needs stability. One cluster forces one upgrade cadence.

    7) Quotas/limits hit sooner
    Example: IPs (VPC CNI), ENIs, security group rules, or API rate limits get exhausted by non-prod churn, blocking prod scaling.

    8) Observability and incident response get messy
    Example: Alerts fire due to non-prod experiments; prod signals get buried, increasing MTTR.


ğŸŒ Networking & VPC Scenarios

1. Your application is running inside Kubernetes pods (on EKS), the database (RDS - Relational Database Service) 
    is in the same AWS VPC, but the app cannot connect to the database (timeouts / connection refused).
    Chapter 1: â€œSame VPC â‰  same permissionâ€
        You remember: AWS networking is deny-by-default.
        Your pod sends a request: â€œHey RDS, are you there?â€
        RDS checks its security group and says: â€œWho are you?â€
        You look at the inbound rules and realize: RDS allows traffic from some CIDR
        But not from the EKS nodes or pod security group
        No rule â†’ no connection â†’ timeout.
    
    Chapter 2: The packet gets lost on the way back
        1. App sends a request â†’ reaches RDS successfully
        2. RDS sends the response back
        3. NACL blocks the outbound response
        4. App waitsâ€¦ and waitsâ€¦
            No error, No rejection, Just a timeout.
        You check the Network ACL.
            Inbound: DB port allowed âœ…
            Outbound: response traffic blocked âŒ
    
    Chapter 3: â€œAre we even calling the right door?â€
        Everything looks correct now. Security Groups fixed. Network ACLs verified
        Yet the app still canâ€™t connect, So you stop staring at the networkâ€¦ and read the config.
        And there it is. The application is trying to connect to the public RDS endpoint.
        But this RDS instance was created with Public access = No. So whatâ€™s happening?
        The pod is inside the VPC, politely knocking on a public door that was never built.
        No listener, No route, Nothing to answer.
        The packets go outâ€¦ and disappear.
        From the appâ€™s point of view:
        â€œI tried. Nobody replied.â€ â†’ timeout
        You update the config:
        Switch to the private RDS endpoint
        Suddenly:
        The door exists, The network path is valid, The database answers
    
    Chapter 4: â€œKubernetes says NOâ€
        Youâ€™ve checked everything outside the cluster.
        Security Groups âœ…
        Route tables âœ…
        NACLs âœ…
        Stillâ€¦ no connection.
        Then it hits you.
        â€œWaitâ€¦ we enabled NetworkPolicies.â€
        You open the policy.
        There it is.
        An egress rule that says:
        Pods may only talk to cluster services
        That means:
        Services inside the cluster â†’ allowed
        Anything outside the cluster â†’ denied
        And RDS?
        It lives outside Kubernetes.
        So whatâ€™s actually happening?
        The pod tries to connect to RDS.
        The packet doesnâ€™t even leave the node.
        Kubernetes looks at the request and says:
        â€œYouâ€™re not allowed to go there.â€
        No AWS logs.
        No firewall errors.
        Just a silent drop.
        From the appâ€™s point of view:
        â€œConnection attemptâ€¦ timeout.â€
        You update the NetworkPolicy:
        Allow egress to the RDS subnet / CIDR
        Or allow the DB port explicitly
        Retry.
        Connection succeeds.

    Chapter 5: â€œConnection refusedâ€ (a very different meaning)
        This time, the error message changes.
        Not a timeout.
        Instead:
        connection refused
        Thatâ€™s an important clue.
        It means the network worked.
        The packet reached the RDS host.
        The host replied immediately.
        But the reply was:
        â€œNothing is listening here.â€
        Why would that happen?
        The app is using the wrong port
        The DB isnâ€™t ready yet (starting, failover, maintenance)
        The wrong engine endpoint (Postgres vs MySQL, reader vs writer)
        So what actually happened?
        The pod knocked on the door.
        The door existed.
        Someone answeredâ€¦
        â€¦but said:
        â€œThis is the wrong door.â€
        No firewalls.
        No policies.
        No routing issues.
        Just configuration mismatch.

2. External traffic reaches the ALB but never reaches pods. How do you debug?
    Journey of HTTP request
        Client â†’ ALB: Client hits ALB DNS; request reaches the listener.
        Listener â†’ Rules: Listener evaluates rules and picks a target group.
        Rules â†’ Target Group: Target group decides where to forward traffic.
        Target Group â†’ NodePort / Pod IP: ALB forwards to a nodeâ€™s NodePort (instance) or directly to a pod IP (ip).
        Node/Pod â†’ Service: Kubernetes Service receives traffic and applies routing logic.
        Service â†’ Endpoints: Service maps to healthy pod IPs via Endpoints/EndpointSlices.
        Endpoints â†’ Pods: Traffic is delivered to one Ready pod running the app.

    1) Start at the ALB: â€œAre my backends even alive?â€
        You donâ€™t touch Kubernetes yet. You open the AWS Console and walk up to the ALB.
        ALB asks its Target Group: â€œAre my targets healthy?â€
        You click:
        ALB â†’ Target Groups â†’ Targets
        And you see it:
        Unhealthy.
        That tells you something important: The ALB tried to reach your backendâ€¦ and failed.
        Now you read why.
        Common stories behind â€œUnhealthyâ€: 
            ALB knocked on the wrong port â†’ nobody answered
            ALB asked for /health but the app only serves /actuator/health
            A security group slammed the door
            Kubernetes says no Ready pods, so targets exist but arenâ€™t usable
        You donâ€™t guess.
        You open:
        Target Group â†’ Health check â†’ Target health reason
        And the ALB literally tells you:
        â€œHereâ€™s why I couldnâ€™t reach them.â€

    2) â€œDid Kubernetes wire the doors correctly?â€
        The ALB exists.
        But now you ask a different question: â€œDid my Ingress tell AWS the right things?â€
        You run: kubectl describe ingress <name>
        You read it like a wiring diagram.
        You check:
            Is the host/path what the client is actually calling?
            Does it point to the right Service name?
            Is the Service port correct (number vs name)?
            Do the annotations say what you expect?
                internet-facing vs internal
                target-type = ip or instance
                correct health check path

        One wrong value here means: ALB exists, but itâ€™s wired to the wrong backend.
        Still not convinced?
        You go one level deeper â€” the controllerâ€™s voice.
        kubectl -n kube-system logs deploy/aws-load-balancer-controller --tail=200
        This is where the controller speaks plainly.
        If something is wrong, it tells you:
            â€œService not foundâ€
            â€œPort mismatchâ€
            â€œFailed to register targetsâ€
            â€œHealth check path invalidâ€
        At this point, youâ€™re not guessing anymore.
            Either:
            The Ingress was translated correctly â†’ move on
            Or:
            The controller explains exactly why traffic never reaches pods
    
    3) â€œIs Kubernetes even sending traffic to anyone?â€
        Now you step fully inside the cluster.
        You ask the Service: â€œWho do you forward traffic to?â€
        You run:
            kubectl get svc <svc>
            kubectl get endpoints <svc>
        If you see no endpoints, thatâ€™s a big clue.
        It means:
        The Service is calling for podsâ€¦
        â€¦but nobody answers
        Why?

        Two usual reasons:
            The Service selector doesnâ€™t match pod labels
            The pods exist, but Kubernetes says theyâ€™re not Ready

        So you follow the selector.
            kubectl get pods -l <selector> -o wide
        You pick a pod and look closer.
            kubectl describe pod <pod>

        And there it is.
        The readiness probe is failing.
        From Kubernetesâ€™ point of view:
        â€œThis pod is alive, but Iâ€™m not ready to send traffic to it.â€
        So the Service keeps the endpoint list empty.

    4) â€œIs the ALB going to the nodeâ€¦ or straight to the pod?â€ (classic trap)
        You think traffic is going to podsâ€¦ but the ALB might be aiming at a totally different â€œdoorâ€.
        If target-type = instance
        The ALB says:
        â€œIâ€™ll talk to the EC2 node.â€
        So it sends traffic to:
        Node IP : NodePort
        That only works if:
        Your Service exposes a NodePort (or LoadBalancer which also has a NodePort)
        That NodePort is reachable (security group / NACL allows it)
        If NodePort isnâ€™t open â†’ ALB health checks fail â†’ no traffic reaches pods.
        If target-type = ip
        The ALB says:
        â€œIâ€™ll talk to the pod directly.â€
        So it sends traffic to:
        Pod IP : containerPort
        That only works if:
        Pod networking (CNI) is working
        Subnets/routing allow ALB â†’ pod IP reachability
        Security group rules allow traffic to pod ENIs (esp. if using SG for Pods)
        How you confirm the truth
        Check:
        AWS Target Group â†’ target type
        Your Ingress annotation:
        alb.ingress.kubernetes.io/target-type: instance|ip
    
    5) â€œIs the ALB even allowed to talk to the backend?â€ (most common prod miss)
        You open the ALB console and it looks fineâ€¦ but networking is just doors and permissions.
        The ALB tries to health-check a target.
        But at the security gate, it gets stopped.
        There are two common storylines:
        If target-type = instance (ALB â†’ node)
        ALB says: â€œIâ€™m going to the nodeâ€™s NodePort.â€
        So you must allow:
        ALB SG outbound â†’ to node SG on the NodePort range (30000â€“32767) (or the specific NodePort)
        Node SG inbound â†’ from ALB SG on that NodePort range
        If node SG doesnâ€™t allow it, the ALB health check never reaches kube-proxy â†’ targets stay Unhealthy.
        If target-type = ip (ALB â†’ pod)
        ALB says: â€œIâ€™m going straight to the pod IP.â€
        So you must allow:
        ALB SG outbound â†’ to the pod ENI SG on the pod/container port
        If you use Security Groups for Pods, the podâ€™s SG must explicitly allow inbound from the ALB SG
        If that SG link is missing, packets die before the pod sees them.
        Why this shows up as â€œtargets unhealthyâ€
        Because from the ALBâ€™s perspective:
        â€œI tried to connect, but I never got a valid response.â€
        So when you see:
        health checks failing
        targets Unhealthy
        â€¦your first suspect is SG (and sometimes NACL) blocking ALB â†’ backend traffic.

    6) â€œThe ALB is checking the wrong pulse.â€
        Your app is aliveâ€¦ but the ALB keeps declaring it dead.
        Why?
        Because the ALB health checker walks up to the backend and asks:
        â€œGive me GET / on port X.â€
        But your app only answers health at:
        GET /actuator/health (or /health) on port Y
        So the ALB gets a 404 / 401 / timeout, and decides:
        â€œTarget is unhealthy.â€
        Then it stops sending real traffic to it.

    7) â€œThe ALB says â€˜healthyâ€™â€¦ but the app still says â€˜noâ€™.â€
        At this point the ALB is happy: targets are healthy, health checks pass.
        So the road up to the cluster is fine.
        But real requests still â€œvanishâ€.
        That usually means the block is inside the cluster or inside the app, like:
        NetworkPolicy / mTLS: traffic is allowed for health checks but real paths/ports/identities get blocked.
        App-level reject: wrong Host header or path, so the app returns 404/401 or routes nowhere.
        Port mismatch: Service sends to port A, but app is listening on port B.
        Quick isolation (bypass ALB completely)
        You talk to the Service directly from your laptop:
        kubectl port-forward svc/<svc> 8080:<port>
        curl -v http://localhost:8080/<path>
        If this fails â†’ itâ€™s Service/Pods/App config (not ALB).
        If this works â†’ the app is fine, so look at Ingress rules/headers/mTLS/policy on the external path.

3. Pods cannot reach the internet, but nodes can. Whatâ€™s the likely cause?

4. Suddenly, new pods fail to start with no clear error. Later you find subnets are exhausted. How did this happen?
    â€œBecause EKS VPC CNI assigns real subnet IPs to pods, scaling nodes/pods and ENI pre-allocation can consume
    IPs quickly; with small subnets, you hit IP exhaustion and new pods fail to start.â€

5. Inter-pod communication fails across nodes but works on the same node. Why?
    1ï¸âƒ£ â€œIt works on the same nodeâ€¦ but dies crossing the street.â€
        You deploy two pods.
        When they land on the same node â†’ they talk just fine âœ…
        (they use the local Linux bridge, no real networking involved)
        Then Kubernetes spreads them out.
        Now one pod is on Node A, the other on Node B.
        Suddenly:
        Requests hang
        Random timeouts appear
        Some pods never even start (ContainerCreating)
        What changed?
        The traffic now has to leave the node.
        Thatâ€™s where the CNI plugin steps in.
        The CNIâ€™s job is to:
        Assign pod IPs
        Program routes
        Attach ENIs (in EKS)
        Make sure packets know how to reach the other node
        If the CNI is broken or misconfigured:
        Routes arenâ€™t programmed
        ENIs/IPs arenâ€™t attached correctly
        Packets leave Node Aâ€¦ and get lost
        So you get the classic symptom:
        Same-node communication works
        Cross-node communication fails
        From the outside it looks random.
        In reality, the pod network fabric is torn.
    
    2ï¸âƒ£ Security Groups block node-to-node traffic
        Each node is an EC2 instance with a security group.
        If the SG:
        allows inbound only from ALB
        but blocks traffic from other nodes
        Then:
        pod â†’ pod on same node works
        pod â†’ pod on another node is dropped by SG
        This is VERY common in locked-down environments.

    3ï¸âƒ£ NetworkPolicy blocks cross-node traffic
        NetworkPolicies donâ€™t care about nodes â€” they care about pod-to-pod rules.
        Example:
        Policy allows traffic from podSelector
        But traffic coming from another node doesnâ€™t match (due to labels / namespaces)
        Result:
        Local traffic allowed
        Remote traffic denied

    4ï¸âƒ£ â€œThe packet crossesâ€¦ but canâ€™t come back.â€
        Two pods are on different nodes:
        Pod A on Node A
        Pod B on Node B
        For them to talk, the packet has to leave one subnet path and come back.
        So it must pass through:
        the subnet route tables
        the Network ACLs on the subnets
        Hereâ€™s the twist: NACLs are stateless.
        Meaning:
        If you allow the request one way, you must also allow the response back.
        So when a NACL is misconfigured like this:
        Inbound allowed âœ…
        Outbound blocked âŒ (or the reverse)
        What happens looks â€œmysteriousâ€:
        Packet leaves Node A âœ…
        Reaches Node B âœ…
        Node B tries to reply
        Reply gets dropped at the subnet boundary âŒ
        Pod A waitsâ€¦ and times out
        So you get the classic symptom:
        Some traffic appears to go through
        But connections hang because the return path is black-holed

ğŸ–¥ï¸ Worker Node & Node Group Scenarios

A node goes NotReady randomly and recovers on its own. What do you suspect?

After upgrading node AMIs, applications start failing intermittently. Why?

Cluster Autoscaler keeps adding nodes, but pods still donâ€™t schedule. Whatâ€™s wrong?

A node group upgrade causes partial outage. What was missed?

Pods are unevenly distributed across nodes causing hot spots. How do you fix it?

ğŸ” IAM, IRSA & Access Scenarios

1. Pods suddenly lose access to S3 even though IAM roles werenâ€™t changed. Why?
    1) The role existsâ€¦ but the pod stopped receiving credentials (IRSA / EKS Pod Identity)
    Yesterday your pod could reach S3. Today it canâ€™t.
    IAM role didnâ€™t change â€” so you assume permissions are fine.
    But the real problem is earlier in the chain:
    The app isnâ€™t getting valid temporary credentials anymore.
    That can happen when:
    Refresh path broke: the pod had creds, they expired, and the SDK canâ€™t refresh (webhook/agent/sidecar issue).
    IRSA token broke: the pod presents a bad OIDC token â†’ AWS returns InvalidIdentityToken 
    (OIDC provider/thumbprint/issuer mismatch, wrong SA annotation, etc.).
    EKS Pod Identity components broke: the webhook didnâ€™t mutate the pod or the agent isnâ€™t running, 
    so the pod never gets identity wired.

    2) The â€œaccessâ€ didnâ€™t break â€” the path broke (network/DNS)
        Even with perfect IAM, your pod still has to reach AWS:
        STS (to mint/refresh creds)
        S3 (to use them)
        If that path changes, it looks like an access issue, but itâ€™s really connectivity.
        What usually causes it
        NAT / egress broken (private subnet route to NAT missing, NAT down, firewall tightened)
        NACL / SG blocks outbound or return traffic
        Route table changes in private subnets
        DNS issues (CoreDNS unhealthy, node /etc/resolv.conf wrong, DNS blocked)
        VPC endpoints changed (S3/STS endpoint not associated with the subnet/route tables anymore, policy tightened)
    
    3) â€œRole is fineâ€ â€” but a different guard is denying you
        Your pod assumes the same role as before, and the role policy didnâ€™t changeâ€¦
        yet S3 returns 403 AccessDenied.
        That usually means the deny is coming from outside the role â€” one of these â€œouter wallsâ€:
        A) S3 Bucket Policy
        The bucket owner can add an explicit Deny or new conditions (IP, VPC, TLS, prefixes, encryption headers).
        Even if IAM allows, explicit deny wins â†’ AccessDenied.
        B) VPC Endpoint policy / VPC-bound conditions
        If you use an S3 Gateway/Interface endpoint, policies/conditions might require traffic to come via:
        aws:SourceVpce (specific endpoint ID)
        aws:SourceVpc (specific VPC)
        or deny public/NAT paths
        If the endpoint association/ID or routes changed, requests start failing with 403 even though IAM didnâ€™t change.
        C) Org-level controls: SCP / Permission Boundary
        An SCP (AWS Organizations) or a permission boundary can silently reduce what the role can do.
        Role policy stays the same, but effective permissions shrink.

2. A pod works with node IAM role but fails after enabling IRSA. What went wrong?

3. Developers ask for admin access to the cluster for debugging. How do you handle this safely?

4. One service can access AWS resources it shouldnâ€™t. How do you audit and fix it?

5. A new engineer cannot access the cluster despite IAM permissions. What did you forget?
    Exactly â€” in EKS there are 3 separate gates, and people often open only the first.
    What you missed (story version)
    You gave them IAM perms, so they can do AWS-side things like eks:DescribeCluster.
    They run kubectlâ€¦ and Kubernetes still says â€œwho are you?â€ or â€œnoâ€.
    Because IAM â‰  Kubernetes access.
    The 3-gate mental model
    IAM = lets them call AWS APIs (e.g., get cluster endpoint/cert).
    EKS auth mapping = lets that IAM principal authenticate to the Kubernetes API
    old: aws-auth ConfigMap mapping to k8s user/groups
    new: EKS Access Entry + access policy
    Kubernetes RBAC = decides what they can do after login (RoleBinding/ClusterRoleBinding).
    Fast error â†’ diagnosis
    â€œYou must be logged in to the serverâ€ â†’ they arenâ€™t mapped for auth (missing aws-auth / Access Entry).
    â€œForbiddenâ€ â†’ they authenticated, but lack RBAC (missing RoleBinding/ClusterRoleBinding).
    Thatâ€™s the full picture: IAM gets you to the door, mapping lets you enter, RBAC decides where you can go inside.

ğŸš€ Deployments & Workload Scenarios

Pods keep restarting with CrashLoopBackOff but logs look fine. What do you check next?

Rolling deployment causes user-visible downtime. Why?

A deployment works in staging but fails in production only under load. Why?

Pods remain in Pending state forever. What are the top 5 things you check?

One bad pod affects the entire nodeâ€™s performance. How do you prevent this?

âš–ï¸ Autoscaling & Performance Scenarios

HPA scales pods aggressively but performance degrades. Why?

Cluster Autoscaler keeps scaling nodes up and down every few minutes. Whatâ€™s wrong?

Kafka consumers scale up but throughput doesnâ€™t improve. Why?

CPU is low, memory is high, but HPA doesnâ€™t scale. What did you miss?

Autoscaling works in test but not in prod. Why?

ğŸŒ Load Balancing & Ingress Scenarios

ALB is created but shows all targets as unhealthy. How do you debug?

One path works on ALB, another returns 404 even though service exists. Why?

Internal services are accidentally exposed publicly. How did this happen?

TLS works for one domain but not another on the same ALB. Why?

Traffic spikes cause ALB 5xx errors during deployments. How do you fix it?

ğŸ’¾ Storage & Stateful Workloads

Pods using PVCs get stuck during rescheduling. Why?

After node failure, stateful pods donâ€™t recover. What went wrong?

Application performance drops after moving from EC2 disks to EBS. Why?

Multiple pods try to mount the same EBS volume and fail. Why?

A StatefulSet loses data after restart. How is that possible?

ğŸ” Observability & Debugging Scenarios

Pods restart but no logs are available. How do you debug?

Metrics show everything is healthy, but users report outages. Why?

DNS resolution fails intermittently inside the cluster. What causes this?

Liveness probe keeps killing healthy pods. Why?

You cannot reproduce a prod issue locally. How do you debug it in EKS?

ğŸ”„ Upgrade & Maintenance Scenarios

EKS control plane upgrade succeeds, but workloads break. Why?

Deprecated APIs cause failures after upgrade. How do you avoid this?

Node upgrades trigger Kafka rebalances and downtime. How do you prevent it?

During maintenance, pods are evicted too aggressively. What was missing?

How do you design zero-downtime cluster upgrades?

ğŸ”¥ Security & Incident Scenarios

A pod is compromised. How do you contain blast radius?

A container image vulnerability is reported in production. What do you do immediately?

A service account has cluster-admin accidentally. How do you detect this?

Secrets were leaked via logs. How do you prevent this permanently?

Compliance asks for namespace isolation guarantees. How do you design it?

ğŸ§  Senior / Architect-Level Scenarios

One giant EKS cluster vs multiple clusters â€” production outage occurs. What do you change?

A â€œnoisy neighborâ€ workload affects critical services. How do you isolate?

Teams deploy whatever they want, causing chaos. How do you enforce standards?

DR region has EKS cluster but traffic switch fails. Why?

If you were to redesign your EKS platform today, what would you do differently?